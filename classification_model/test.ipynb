{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07e3d3a-1ce2-4d25-a477-780f48d2dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import wfdb\n",
    "from tensorflow import keras\n",
    "from tensorflow import lite\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f70d3-e85d-46fc-8a45-7fe9a365c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = '../../../Datasets/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1\\\\'\n",
    "sampling_rate=100\n",
    "calssificatin_type = \"superclasses\"    #{\"binary\",\"superclasses\",\"subclasses\"}\n",
    "\n",
    "lead_types={\"lead-I\":[1,2,3,4,5,6,7,8,9,10,11], \"bipolar-limb\":[3,4,5,6,7,8,9,10,11] , \"unipolar-limb\":[0,1,2,6,7,8,9,10,11], \"limb-leads\":[6,7,8,9,10,11] , \"precordial-leads\":[0,1,2,3,4,5],\"all-lead\":[]}\n",
    "lead_name=\"all-lead\"\n",
    "\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_superclass_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "def aggregate_subclass_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_subclass)\n",
    "    ret = list(set(tmp))\n",
    "    return ret\n",
    "\n",
    "if calssificatin_type == \"superclasses\":\n",
    "    Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_superclass_diagnostic)\n",
    "else:\n",
    "    Y['diagnostic_subclass'] = Y.scp_codes.apply(aggregate_subclass_diagnostic)\n",
    "    \n",
    "# Ensure y_train is correctly transformed\n",
    "mlb = MultiLabelBinarizer(classes=['CD', 'HYP', 'MI', 'NORM', 'STTC'])\n",
    "Y = mlb.fit_transform(Y.diagnostic_superclass)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965774b-8ac3-4fd4-bf01-e4ccb8e84184",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(X)\n",
    "X2 = []\n",
    "for i in range(len(X1)):\n",
    "    X2.append(X1[i].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a09bb-312b-4c02-ac37-87219753b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split from sklearn.model_selection for splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting the dataset into test and train dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print lenght of thest and train dataset\n",
    "print(\"Training data:\")\n",
    "print(len(X_train))\n",
    "print(\"Training labels:\")\n",
    "print(len(y_train))\n",
    "print(\"Testing data:\")\n",
    "print(len(X_test))\n",
    "print(\"Testing labels:\")\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3378294-3ebe-4512-930c-c05b8ac23a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
      "[[0.72913176 0.15022688 0.37553376 0.09492628 0.13110994]]\n",
      "Prediction : [1, 0, 0, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "[[0.26098523 0.09586097 0.2846017  0.4275405  0.15254761]]\n",
      "Prediction : [0, 0, 0, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "[[0.1121065  0.05071908 0.08830016 0.67902625 0.17704579]]\n",
      "Prediction : [0, 0, 0, 1, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8469813  0.11002915 0.5514455  0.02488077 0.11463881]]\n",
      "Prediction : [1, 0, 1, 0, 0]\n",
      "True : [1 0 0 0 0]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BB29E7D510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BB29E7D510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "[[0.22788322 0.06595701 0.15564668 0.5503494  0.094343  ]]\n",
      "Prediction : [0, 0, 0, 1, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BB0B03D510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BB0B03D510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "[[0.07737277 0.05818404 0.13245194 0.7391355  0.11227228]]\n",
      "Prediction : [0, 0, 0, 1, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
      "[[0.867604   0.06324558 0.55454665 0.00229225 0.08578717]]\n",
      "Prediction : [1, 0, 1, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "[[0.7694133  0.21265079 0.4889134  0.01387787 0.10201441]]\n",
      "Prediction : [1, 0, 0, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "[[0.14929284 0.24329165 0.18547256 0.18934555 0.35345677]]\n",
      "Prediction : [0, 0, 0, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "[[0.26354086 0.08279222 0.24480692 0.16065939 0.47710305]]\n",
      "Prediction : [0, 0, 0, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "[[0.46568203 0.12421826 0.38397053 0.2488414  0.28161696]]\n",
      "Prediction : [0, 0, 0, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "[[0.42542085 0.09477528 0.3037608  0.35625517 0.14786705]]\n",
      "Prediction : [0, 0, 0, 0, 0]\n",
      "True : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# testing the models with given data index (i)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for j in range(12):\n",
    "    model = tf.keras.models.load_model(f'trial_2_{j+1}_model.h5')\n",
    "    input_data = X_test[i-1][j]\n",
    "    input_data = input_data.reshape(1, 1000, 1) \n",
    "    predictions = model.predict(input_data)\n",
    "    print(predictions)\n",
    "    print(f\"Prediction : {[1 if x > 0.5 else 0 for x in predictions[0]]}\")\n",
    "    print(f\"True : {y_test[i-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0ed2c4-d338-4e5a-b958-c74f4096b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save test 12 lead data as CSV file with transposed data\n",
    "\n",
    "# for i in range(len(X_test)):\n",
    "#     df = pd.DataFrame(X_test[i])\n",
    "#     df.to_csv(f'../12_lead_test_data/12_lead_ecg_test_{i}.csv', index = False)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c76cff7-19db-44c3-b555-f6d4fefafd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# for i in range(5):\n",
    "#     plt.plot(X_train[i])\n",
    "#     plt.title(y_train[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2127d-3060-4560-85c6-5e9ac13587be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

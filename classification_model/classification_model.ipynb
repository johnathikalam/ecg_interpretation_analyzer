{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f652f6-29be-4103-9fe6-826d70c5594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import wfdb\n",
    "from tensorflow import keras\n",
    "from tensorflow import lite\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508d6729-38fe-409b-b31e-099e27cb986d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = '../../../Datasets/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1\\\\'\n",
    "\n",
    "sampling_rate=100\n",
    "calssificatin_type = \"superclasses\"    #{\"binary\",\"superclasses\",\"subclasses\"}\n",
    "\n",
    "lead_types={\"lead-I\":[1,2,3,4,5,6,7,8,9,10,11], \"bipolar-limb\":[3,4,5,6,7,8,9,10,11] , \"unipolar-limb\":[0,1,2,6,7,8,9,10,11], \"limb-leads\":[6,7,8,9,10,11] , \"precordial-leads\":[0,1,2,3,4,5],\"all-lead\":[]}\n",
    "lead_name=\"all-lead\"\n",
    "\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_superclass_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "def aggregate_subclass_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_subclass)\n",
    "    ret = list(set(tmp))\n",
    "    return ret\n",
    "\n",
    "if calssificatin_type == \"superclasses\":\n",
    "    Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_superclass_diagnostic)\n",
    "else:\n",
    "    Y['diagnostic_subclass'] = Y.scp_codes.apply(aggregate_subclass_diagnostic)\n",
    "    \n",
    "# Ensure y_train is correctly transformed\n",
    "mlb = MultiLabelBinarizer(classes=['CD', 'HYP', 'MI', 'NORM', 'STTC'])\n",
    "Y = mlb.fit_transform(Y.diagnostic_superclass)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e68b9f-0299-4787-a717-e7d306559601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1000, 1)),\n",
    "        tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv1D(256, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv1D(512, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(5, activation='sigmoid')  # Output layer with 5 elements\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f6365-8df9-43cc-ac22-946747b7c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 455ms/step - accuracy: 0.3400 - loss: 0.5830 - val_accuracy: 0.4139 - val_loss: 0.5263\n",
      "Epoch 2/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 453ms/step - accuracy: 0.4324 - loss: 0.5276 - val_accuracy: 0.4629 - val_loss: 0.4707\n",
      "Epoch 3/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 446ms/step - accuracy: 0.4702 - loss: 0.4828 - val_accuracy: 0.5311 - val_loss: 0.4400\n",
      "Epoch 4/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 440ms/step - accuracy: 0.5337 - loss: 0.4473 - val_accuracy: 0.5311 - val_loss: 0.4249\n",
      "Epoch 5/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 435ms/step - accuracy: 0.5393 - loss: 0.4368 - val_accuracy: 0.5449 - val_loss: 0.4215\n",
      "Epoch 6/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 434ms/step - accuracy: 0.5445 - loss: 0.4299 - val_accuracy: 0.5321 - val_loss: 0.4406\n",
      "Epoch 7/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 442ms/step - accuracy: 0.5449 - loss: 0.4257 - val_accuracy: 0.5579 - val_loss: 0.4101\n",
      "Epoch 8/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 444ms/step - accuracy: 0.5486 - loss: 0.4227 - val_accuracy: 0.5655 - val_loss: 0.4050\n",
      "Epoch 9/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 438ms/step - accuracy: 0.5545 - loss: 0.4144 - val_accuracy: 0.5538 - val_loss: 0.4026\n",
      "Epoch 10/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 443ms/step - accuracy: 0.5646 - loss: 0.4043 - val_accuracy: 0.5595 - val_loss: 0.4067\n",
      "Epoch 11/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 430ms/step - accuracy: 0.5656 - loss: 0.4022 - val_accuracy: 0.5652 - val_loss: 0.4020\n",
      "Epoch 12/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 399ms/step - accuracy: 0.5673 - loss: 0.3993 - val_accuracy: 0.5650 - val_loss: 0.4024\n",
      "Epoch 13/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 399ms/step - accuracy: 0.5782 - loss: 0.3936 - val_accuracy: 0.5698 - val_loss: 0.4024\n",
      "Epoch 14/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 309ms/step - accuracy: 0.5775 - loss: 0.3911 - val_accuracy: 0.5646 - val_loss: 0.4022\n",
      "Epoch 15/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 261ms/step - accuracy: 0.5884 - loss: 0.3816 - val_accuracy: 0.5611 - val_loss: 0.4053\n",
      "Epoch 16/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 256ms/step - accuracy: 0.5897 - loss: 0.3774 - val_accuracy: 0.5614 - val_loss: 0.4185\n",
      "Epoch 17/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 269ms/step - accuracy: 0.5899 - loss: 0.3724 - val_accuracy: 0.5662 - val_loss: 0.4038\n",
      "Epoch 18/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 270ms/step - accuracy: 0.5969 - loss: 0.3633 - val_accuracy: 0.5646 - val_loss: 0.4109\n",
      "Epoch 19/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 281ms/step - accuracy: 0.6070 - loss: 0.3591 - val_accuracy: 0.5623 - val_loss: 0.4186\n",
      "Epoch 20/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 272ms/step - accuracy: 0.6104 - loss: 0.3531 - val_accuracy: 0.5627 - val_loss: 0.4155\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.5736 - loss: 0.4112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.4154638350009918\n",
      "Test accuracy: 0.5627289414405823\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmphhy6urjn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmphhy6urjn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\John\\AppData\\Local\\Temp\\tmphhy6urjn'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1000, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2617515112432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461525488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461536576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461532528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461537280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461534992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461537456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461537808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461537632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461984944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461538160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461984768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461985824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461985472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "model 1 saved\n",
      "Epoch 1/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 286ms/step - accuracy: 0.3714 - loss: 0.5742 - val_accuracy: 0.5337 - val_loss: 0.5141\n",
      "Epoch 2/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 343ms/step - accuracy: 0.4864 - loss: 0.5117 - val_accuracy: 0.5744 - val_loss: 0.4473\n",
      "Epoch 3/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 294ms/step - accuracy: 0.5357 - loss: 0.4622 - val_accuracy: 0.5847 - val_loss: 0.4240\n",
      "Epoch 4/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 284ms/step - accuracy: 0.5601 - loss: 0.4384 - val_accuracy: 0.5939 - val_loss: 0.4123\n",
      "Epoch 5/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 271ms/step - accuracy: 0.5730 - loss: 0.4198 - val_accuracy: 0.6142 - val_loss: 0.3958\n",
      "Epoch 6/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 281ms/step - accuracy: 0.5807 - loss: 0.4170 - val_accuracy: 0.6030 - val_loss: 0.4203\n",
      "Epoch 7/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 285ms/step - accuracy: 0.5974 - loss: 0.4020 - val_accuracy: 0.6184 - val_loss: 0.3829\n",
      "Epoch 8/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 290ms/step - accuracy: 0.6017 - loss: 0.3961 - val_accuracy: 0.6195 - val_loss: 0.3859\n",
      "Epoch 9/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 275ms/step - accuracy: 0.6075 - loss: 0.3913 - val_accuracy: 0.6156 - val_loss: 0.3892\n",
      "Epoch 10/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 269ms/step - accuracy: 0.6154 - loss: 0.3806 - val_accuracy: 0.6124 - val_loss: 0.3875\n",
      "Epoch 11/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 394ms/step - accuracy: 0.6140 - loss: 0.3791 - val_accuracy: 0.6147 - val_loss: 0.3856\n",
      "Epoch 12/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 390ms/step - accuracy: 0.6258 - loss: 0.3708 - val_accuracy: 0.6211 - val_loss: 0.3759\n",
      "Epoch 13/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 398ms/step - accuracy: 0.6328 - loss: 0.3639 - val_accuracy: 0.6092 - val_loss: 0.3821\n",
      "Epoch 14/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 387ms/step - accuracy: 0.6325 - loss: 0.3607 - val_accuracy: 0.6190 - val_loss: 0.3825\n",
      "Epoch 15/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 340ms/step - accuracy: 0.6375 - loss: 0.3570 - val_accuracy: 0.6209 - val_loss: 0.3840\n",
      "Epoch 16/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 361ms/step - accuracy: 0.6377 - loss: 0.3566 - val_accuracy: 0.6197 - val_loss: 0.3821\n",
      "Epoch 17/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 362ms/step - accuracy: 0.6442 - loss: 0.3448 - val_accuracy: 0.6136 - val_loss: 0.3938\n",
      "Epoch 18/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 373ms/step - accuracy: 0.6522 - loss: 0.3366 - val_accuracy: 0.6225 - val_loss: 0.3871\n",
      "Epoch 19/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 350ms/step - accuracy: 0.6588 - loss: 0.3348 - val_accuracy: 0.6083 - val_loss: 0.4113\n",
      "Epoch 20/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 379ms/step - accuracy: 0.6646 - loss: 0.3217 - val_accuracy: 0.6165 - val_loss: 0.3842\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.6259 - loss: 0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3841567933559418\n",
      "Test accuracy: 0.6165292859077454\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmp8stsd0dw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmp8stsd0dw\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\John\\AppData\\Local\\Temp\\tmp8stsd0dw'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1000, 1), dtype=tf.float32, name='keras_tensor_19')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2617515797568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515798624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515800560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515799328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515806032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515803216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515807792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515804800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515807264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515808144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515808320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515809904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515810080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515811664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "model 2 saved\n",
      "Epoch 1/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 411ms/step - accuracy: 0.3271 - loss: 0.5817 - val_accuracy: 0.4803 - val_loss: 0.5075\n",
      "Epoch 2/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 439ms/step - accuracy: 0.4603 - loss: 0.5218 - val_accuracy: 0.5055 - val_loss: 0.4942\n",
      "Epoch 3/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 436ms/step - accuracy: 0.4789 - loss: 0.5096 - val_accuracy: 0.5092 - val_loss: 0.4841\n",
      "Epoch 4/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 443ms/step - accuracy: 0.4954 - loss: 0.5006 - val_accuracy: 0.5236 - val_loss: 0.4744\n",
      "Epoch 5/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 432ms/step - accuracy: 0.5180 - loss: 0.4864 - val_accuracy: 0.5183 - val_loss: 0.4696\n",
      "Epoch 6/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 437ms/step - accuracy: 0.5045 - loss: 0.4827 - val_accuracy: 0.5238 - val_loss: 0.4656\n",
      "Epoch 7/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 434ms/step - accuracy: 0.5121 - loss: 0.4771 - val_accuracy: 0.5282 - val_loss: 0.4631\n",
      "Epoch 8/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 441ms/step - accuracy: 0.5231 - loss: 0.4662 - val_accuracy: 0.5428 - val_loss: 0.4577\n",
      "Epoch 9/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 409ms/step - accuracy: 0.5211 - loss: 0.4691 - val_accuracy: 0.5357 - val_loss: 0.4573\n",
      "Epoch 10/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 389ms/step - accuracy: 0.5272 - loss: 0.4616 - val_accuracy: 0.5302 - val_loss: 0.4594\n",
      "Epoch 11/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 358ms/step - accuracy: 0.5416 - loss: 0.4513 - val_accuracy: 0.5424 - val_loss: 0.4592\n",
      "Epoch 12/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 371ms/step - accuracy: 0.5400 - loss: 0.4521 - val_accuracy: 0.5453 - val_loss: 0.4580\n",
      "Epoch 13/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 381ms/step - accuracy: 0.5564 - loss: 0.4444 - val_accuracy: 0.5364 - val_loss: 0.4466\n",
      "Epoch 14/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 395ms/step - accuracy: 0.5511 - loss: 0.4411 - val_accuracy: 0.5492 - val_loss: 0.4511\n",
      "Epoch 15/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 364ms/step - accuracy: 0.5621 - loss: 0.4301 - val_accuracy: 0.5501 - val_loss: 0.4449\n",
      "Epoch 16/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 333ms/step - accuracy: 0.5677 - loss: 0.4253 - val_accuracy: 0.5671 - val_loss: 0.4455\n",
      "Epoch 17/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 360ms/step - accuracy: 0.5799 - loss: 0.4171 - val_accuracy: 0.5529 - val_loss: 0.4452\n",
      "Epoch 18/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 359ms/step - accuracy: 0.5754 - loss: 0.4144 - val_accuracy: 0.5572 - val_loss: 0.4598\n",
      "Epoch 19/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 366ms/step - accuracy: 0.5891 - loss: 0.4088 - val_accuracy: 0.5563 - val_loss: 0.4458\n",
      "Epoch 20/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 370ms/step - accuracy: 0.5964 - loss: 0.3948 - val_accuracy: 0.5559 - val_loss: 0.4502\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 92ms/step - accuracy: 0.5637 - loss: 0.4417\n",
      "\n",
      "Test loss: 0.45017191767692566\n",
      "Test accuracy: 0.5558608174324036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmp_35phusx\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmp_35phusx\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\John\\AppData\\Local\\Temp\\tmp_35phusx'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1000, 1), dtype=tf.float32, name='keras_tensor_38')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2617457549984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617457550864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617457557200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617457553328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617457553504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617457555792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617457557024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617449992384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617449990272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617449989920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617449993264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617449992912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617449993088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617449994672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "model 3 saved\n",
      "Epoch 1/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 367ms/step - accuracy: 0.3679 - loss: 0.5802 - val_accuracy: 0.4132 - val_loss: 0.5269\n",
      "Epoch 2/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 404ms/step - accuracy: 0.4431 - loss: 0.5172 - val_accuracy: 0.5888 - val_loss: 0.4165\n",
      "Epoch 3/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 394ms/step - accuracy: 0.5523 - loss: 0.4332 - val_accuracy: 0.5939 - val_loss: 0.3942\n",
      "Epoch 4/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 378ms/step - accuracy: 0.5644 - loss: 0.4146 - val_accuracy: 0.5897 - val_loss: 0.3856\n",
      "Epoch 5/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 379ms/step - accuracy: 0.5818 - loss: 0.4009 - val_accuracy: 0.5982 - val_loss: 0.3856\n",
      "Epoch 6/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 334ms/step - accuracy: 0.5838 - loss: 0.3998 - val_accuracy: 0.5939 - val_loss: 0.3855\n",
      "Epoch 7/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 348ms/step - accuracy: 0.5948 - loss: 0.3866 - val_accuracy: 0.5927 - val_loss: 0.3791\n",
      "Epoch 8/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 344ms/step - accuracy: 0.6000 - loss: 0.3836 - val_accuracy: 0.5952 - val_loss: 0.3747\n",
      "Epoch 9/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 395ms/step - accuracy: 0.5989 - loss: 0.3771 - val_accuracy: 0.5852 - val_loss: 0.3797\n",
      "Epoch 11/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 372ms/step - accuracy: 0.5972 - loss: 0.3730 - val_accuracy: 0.6037 - val_loss: 0.3816\n",
      "Epoch 12/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 297ms/step - accuracy: 0.6123 - loss: 0.3666 - val_accuracy: 0.6051 - val_loss: 0.3684\n",
      "Epoch 13/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 321ms/step - accuracy: 0.6129 - loss: 0.3617 - val_accuracy: 0.5891 - val_loss: 0.3762\n",
      "Epoch 14/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 273ms/step - accuracy: 0.6155 - loss: 0.3597 - val_accuracy: 0.6005 - val_loss: 0.3734\n",
      "Epoch 15/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 283ms/step - accuracy: 0.6234 - loss: 0.3493 - val_accuracy: 0.6033 - val_loss: 0.3796\n",
      "Epoch 16/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 302ms/step - accuracy: 0.6275 - loss: 0.3427 - val_accuracy: 0.5959 - val_loss: 0.3807\n",
      "Epoch 17/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 309ms/step - accuracy: 0.6319 - loss: 0.3395 - val_accuracy: 0.5959 - val_loss: 0.3856\n",
      "Epoch 18/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 326ms/step - accuracy: 0.6416 - loss: 0.3288 - val_accuracy: 0.5886 - val_loss: 0.3933\n",
      "Epoch 19/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 322ms/step - accuracy: 0.6496 - loss: 0.3265 - val_accuracy: 0.5987 - val_loss: 0.3962\n",
      "Epoch 20/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 309ms/step - accuracy: 0.6556 - loss: 0.3161 - val_accuracy: 0.5994 - val_loss: 0.3902\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 86ms/step - accuracy: 0.6125 - loss: 0.3783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.39024627208709717\n",
      "Test accuracy: 0.5993589758872986\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmpa99seq81\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmpa99seq81\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\John\\AppData\\Local\\Temp\\tmpa99seq81'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1000, 1), dtype=tf.float32, name='keras_tensor_57')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2618472544768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618472545824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440343088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440338512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440344848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440342208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440346608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440343616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440346080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440346960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440347136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440348720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440348896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617440350480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "model 4 saved\n",
      "Epoch 1/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 306ms/step - accuracy: 0.3263 - loss: 0.5800 - val_accuracy: 0.4785 - val_loss: 0.5166\n",
      "Epoch 2/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 315ms/step - accuracy: 0.4536 - loss: 0.5244 - val_accuracy: 0.5014 - val_loss: 0.5077\n",
      "Epoch 3/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 292ms/step - accuracy: 0.4754 - loss: 0.5131 - val_accuracy: 0.5101 - val_loss: 0.4865\n",
      "Epoch 4/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 284ms/step - accuracy: 0.4799 - loss: 0.5000 - val_accuracy: 0.5153 - val_loss: 0.4733\n",
      "Epoch 5/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 275ms/step - accuracy: 0.4941 - loss: 0.4878 - val_accuracy: 0.5391 - val_loss: 0.4629\n",
      "Epoch 6/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 287ms/step - accuracy: 0.5118 - loss: 0.4716 - val_accuracy: 0.5366 - val_loss: 0.4532\n",
      "Epoch 7/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 251ms/step - accuracy: 0.5138 - loss: 0.4644 - val_accuracy: 0.5311 - val_loss: 0.4699\n",
      "Epoch 8/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 348ms/step - accuracy: 0.5239 - loss: 0.4572 - val_accuracy: 0.5307 - val_loss: 0.4468\n",
      "Epoch 9/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 381ms/step - accuracy: 0.5279 - loss: 0.4513 - val_accuracy: 0.5412 - val_loss: 0.4548\n",
      "Epoch 10/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 383ms/step - accuracy: 0.5346 - loss: 0.4465 - val_accuracy: 0.5366 - val_loss: 0.4472\n",
      "Epoch 11/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 370ms/step - accuracy: 0.5304 - loss: 0.4440 - val_accuracy: 0.5346 - val_loss: 0.4454\n",
      "Epoch 12/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 335ms/step - accuracy: 0.5357 - loss: 0.4372 - val_accuracy: 0.5206 - val_loss: 0.4473\n",
      "Epoch 13/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 332ms/step - accuracy: 0.5468 - loss: 0.4323 - val_accuracy: 0.5430 - val_loss: 0.4427\n",
      "Epoch 14/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 336ms/step - accuracy: 0.5521 - loss: 0.4291 - val_accuracy: 0.5456 - val_loss: 0.4454\n",
      "Epoch 15/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 320ms/step - accuracy: 0.5554 - loss: 0.4246 - val_accuracy: 0.5440 - val_loss: 0.4533\n",
      "Epoch 16/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 365ms/step - accuracy: 0.5607 - loss: 0.4198 - val_accuracy: 0.5266 - val_loss: 0.4470\n",
      "Epoch 17/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 365ms/step - accuracy: 0.5623 - loss: 0.4140 - val_accuracy: 0.5465 - val_loss: 0.4536\n",
      "Epoch 18/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 354ms/step - accuracy: 0.5704 - loss: 0.4086 - val_accuracy: 0.5321 - val_loss: 0.4454\n",
      "Epoch 19/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 376ms/step - accuracy: 0.5804 - loss: 0.3996 - val_accuracy: 0.5263 - val_loss: 0.4457\n",
      "Epoch 20/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 380ms/step - accuracy: 0.5761 - loss: 0.3977 - val_accuracy: 0.5378 - val_loss: 0.4486\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.5528 - loss: 0.4455\n",
      "\n",
      "Test loss: 0.44858992099761963\n",
      "Test accuracy: 0.5377747416496277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmpkyg4e7om\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmpkyg4e7om\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\John\\AppData\\Local\\Temp\\tmpkyg4e7om'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1000, 1), dtype=tf.float32, name='keras_tensor_76')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2617894091440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617894092496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461413088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461408512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461414848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461412208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461416608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461413616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461416080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461416960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461417136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461418720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461418896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617461420480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "model 5 saved\n",
      "Epoch 1/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 423ms/step - accuracy: 0.3744 - loss: 0.5776 - val_accuracy: 0.5112 - val_loss: 0.5176\n",
      "Epoch 2/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 404ms/step - accuracy: 0.4846 - loss: 0.5246 - val_accuracy: 0.5334 - val_loss: 0.4830\n",
      "Epoch 3/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 414ms/step - accuracy: 0.5073 - loss: 0.4943 - val_accuracy: 0.5353 - val_loss: 0.4664\n",
      "Epoch 4/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 462ms/step - accuracy: 0.5246 - loss: 0.4785 - val_accuracy: 0.5462 - val_loss: 0.4559\n",
      "Epoch 5/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 447ms/step - accuracy: 0.5252 - loss: 0.4668 - val_accuracy: 0.5311 - val_loss: 0.4461\n",
      "Epoch 6/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 432ms/step - accuracy: 0.5453 - loss: 0.4532 - val_accuracy: 0.5412 - val_loss: 0.4420\n",
      "Epoch 7/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 429ms/step - accuracy: 0.5539 - loss: 0.4438 - val_accuracy: 0.5561 - val_loss: 0.4424\n",
      "Epoch 8/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 409ms/step - accuracy: 0.5501 - loss: 0.4378 - val_accuracy: 0.5691 - val_loss: 0.4272\n",
      "Epoch 9/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 416ms/step - accuracy: 0.5632 - loss: 0.4320 - val_accuracy: 0.5746 - val_loss: 0.4261\n",
      "Epoch 10/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 439ms/step - accuracy: 0.5631 - loss: 0.4285 - val_accuracy: 0.5792 - val_loss: 0.4240\n",
      "Epoch 11/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 436ms/step - accuracy: 0.5826 - loss: 0.4182 - val_accuracy: 0.5648 - val_loss: 0.4288\n",
      "Epoch 12/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 441ms/step - accuracy: 0.5843 - loss: 0.4112 - val_accuracy: 0.5877 - val_loss: 0.4175\n",
      "Epoch 13/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 437ms/step - accuracy: 0.5879 - loss: 0.4037 - val_accuracy: 0.5831 - val_loss: 0.4252\n",
      "Epoch 14/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 446ms/step - accuracy: 0.5987 - loss: 0.3984 - val_accuracy: 0.5822 - val_loss: 0.4199\n",
      "Epoch 15/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 406ms/step - accuracy: 0.6034 - loss: 0.3972 - val_accuracy: 0.5794 - val_loss: 0.4200\n",
      "Epoch 16/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 356ms/step - accuracy: 0.6117 - loss: 0.3863 - val_accuracy: 0.5808 - val_loss: 0.4190\n",
      "Epoch 17/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 314ms/step - accuracy: 0.6153 - loss: 0.3789 - val_accuracy: 0.5879 - val_loss: 0.4223\n",
      "Epoch 18/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 329ms/step - accuracy: 0.6165 - loss: 0.3717 - val_accuracy: 0.5765 - val_loss: 0.4278\n",
      "Epoch 19/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 282ms/step - accuracy: 0.6306 - loss: 0.3619 - val_accuracy: 0.5916 - val_loss: 0.4386\n",
      "Epoch 20/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 343ms/step - accuracy: 0.6289 - loss: 0.3603 - val_accuracy: 0.5813 - val_loss: 0.4291\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.5850 - loss: 0.4202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.4290865957736969\n",
      "Test accuracy: 0.5812729001045227\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmphbk76f1p\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\John\\AppData\\Local\\Temp\\tmphbk76f1p\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\John\\AppData\\Local\\Temp\\tmphbk76f1p'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1000, 1), dtype=tf.float32, name='keras_tensor_95')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2617515718112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2617515719168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352816144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352814032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352817904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352815264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352819664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352816672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352819136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352820016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352820192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352821776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352821952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2618352823536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "model 6 saved\n",
      "Epoch 1/20\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.3309 - loss: 0.5821"
     ]
    }
   ],
   "source": [
    "for j in range(12):\n",
    "    X1 = np.array(X)\n",
    "    X2 = []\n",
    "    for i in range(len(X1)):\n",
    "        X2.append(X1[i].transpose())\n",
    "\n",
    "    X2_1 = []\n",
    "    for i in range(len(X2)):\n",
    "        X2_1.append(X2[i][j])\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2_1, Y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # Reshape the data to match the input shape expected by the model\n",
    "    X_train = np.array(X_train).reshape(-1, 1000, 1)\n",
    "    X_test = np.array(X_test).reshape(-1, 1000, 1)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'\\nTest loss: {loss}\\nTest accuracy: {accuracy}')\n",
    "\n",
    "    model.save(f'trial_{j+1}_model.h5')\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tfmodel = converter.convert()\n",
    "    open(f\"ftlite_model/tflite_lead_{j+1}.tflite\",\"wb\").write(tfmodel)\n",
    "\n",
    "    print(f\"model {j+1} saved\")\n",
    "    \n",
    "print(\"Models created sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45833d-61d7-4f32-a6bc-8a57dab27ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
